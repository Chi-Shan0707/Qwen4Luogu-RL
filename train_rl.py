import torch
import torch.nn as nn
import os
from datasets import load_dataset, load_from_disk
from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    BitsAndBytesConfig,
)
from peft import LoraConfig, get_peft_model
from trl import GRPOTrainer, GRPOConfig
from modelscope.hub.snapshot_download import snapshot_download
import optimum
import bitsandbytes as bnb



# ========== æ¨¡å‹é…ç½® ==========
MS_MODEL_ID = "qwen/Qwen2.5-Coder-3B-Instruct"
LOCAL_MODEL_DIR = "./models/Qwen2.5-Coder-3B-Instruct"
OUTPUT_DIR = "./output/luoguqwencoder-lora"

#  Qwen2.5-Coder-3B-Instruct
# ========== ä¸‹è½½æ¨¡å‹ ==========
if not os.path.exists(LOCAL_MODEL_DIR):
    print(f"ä»ModelScopeä¸‹è½½æ¨¡å‹ {MS_MODEL_ID} åˆ° {LOCAL_MODEL_DIR}...")
    snapshot_download(
        repo_id=MS_MODEL_ID,
        local_dir=LOCAL_MODEL_DIR,
    )
    print("æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
else:
    print(f"æœ¬åœ°å·²å­˜åœ¨æ¨¡å‹ï¼Œç›´æ¥åŠ è½½ï¼š{LOCAL_MODEL_DIR}")

# ========== åŠ è½½ tokenizer ==========
tokenizer = AutoTokenizer.from_pretrained(
    LOCAL_MODEL_DIR,
    trust_remote_code=True,
)
tokenizer.pad_token = tokenizer.eos_token
tokenizer.padding_side = "right"


# ========== åŠ è½½æ¨¡å‹ï¼ˆ4bit é‡åŒ–ï¼‰==========
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16,
)
model = AutoModelForCausalLM.from_pretrained(
    LOCAL_MODEL_DIR,
    quantization_config=bnb_config,
    device_map="auto",
    trust_remote_code=True,
    # torch_dtype=torch.bfloat16,
    dtype=torch.bfloat16,
)
model.config.use_cache = False


# ========== åŠ è½½æ•°æ®é›† ==========
# dataset = load_dataset("Misaka114514/luogu_dpo")
dataset = load_from_disk("./local_luogu_dataset")
print("å·²å®Œæˆæ•°æ®é›†åŠ è½½")

# ========== å®šä¹‰ TinyLoRA å±‚ ==========

# åˆ›å»ºä¸€ä¸ªå…¨å±€å…±äº«çš„å‘é‡ v (å®ç°è®ºæ–‡æåˆ°çš„ Tiling)
global_v = nn.Parameter(torch.zeros(16)) 
global_v.requires_grad = True

class TinyLoRALinear(nn.Module):
    def __init__(self, original_layer, rank = 2, u = 16, shared_v =None):
    # R= v_1 P_1 + v_2 P_2 + ... + v_u P_u
    # véƒ½æ˜¯scalar
    # Péƒ½æ˜¯rank x rankçš„çŸ©é˜µ

        super().__init__()
        # å¿…å…ˆç»§æ‰¿çˆ¶ç±»çš„åˆå§‹åŒ–å‡½æ•°ï¼Œæ‰èƒ½ä½¿ç”¨ nn.Module çš„åŠŸèƒ½ï¼ˆä¾‹å¦‚æ³¨å†Œå‚æ•°å’Œç¼“å†²åŒºï¼‰ã€‚
        
        #  super().__init__() æ˜¯ä»€ä¹ˆï¼Ÿ
        # è¿™æ˜¯ Python é¢å‘å¯¹è±¡ç¼–ç¨‹ï¼ˆOOPï¼‰çš„æ ‡å‡†å†™æ³•ã€‚
        # å«ä¹‰ï¼šè°ƒç”¨çˆ¶ç±»ï¼ˆParent Classï¼‰çš„åˆå§‹åŒ–å‡½æ•°ã€‚
        # åœ¨è¿™é‡Œçš„ä½œç”¨ï¼šä½ çš„ç±» TinyLoRALinear ç»§æ‰¿è‡ª nn.Moduleï¼ˆPyTorch çš„ç¥ç»ç½‘ç»œåŸºç±»ï¼‰ã€‚æ‰§è¡Œ super().__init__() æ˜¯ä¸ºäº†è®© PyTorch çš„æœºåˆ¶ç”Ÿæ•ˆï¼Œæ¯”å¦‚ï¼š
        # æ³¨å†Œä½ å®šä¹‰çš„ self.v ä¸ºå¯è®­ç»ƒå‚æ•°ã€‚
        # æ³¨å†Œ self.U, self.S ç­‰ä¸º Bufferï¼ˆä¸è®­ç»ƒçš„å‚æ•°ï¼‰ã€‚


        print(f"original_layer.device: {original_layer.weight.device}, dtype: {original_layer.weight.dtype}")

        original_device = original_layer.weight.device # è®°å½•åŸdevice


        self.base_layer = original_layer

        W = original_layer.weight.data.float()
        if hasattr(original_layer.weight, "quant_state"):
            # 4-bit æƒ…å†µ
            W_real = bnb.functional.dequantize_4bit(
                original_layer.weight.data, 
                original_layer.weight.quant_state
            )
        else:
            # éé‡åŒ–æƒ…å†µ
            W_real = original_layer.weight.data


        W_real_on_cpu = W_real.float().cpu()

        U, S ,Vh = torch.linalg.svd( W_real_on_cpu ,full_matrices=False)

        # SVD åˆ†è§£ W çŸ©é˜µ
        # W = U S Vh 
        # Vhæ˜¯ Vçš„Hermitian transposedï¼Œå…±è½­è½¬ç½®
        # å†»ç»“ U, S, V (LoRA-XS çš„éª¨æ¶)

        

        # å°†ç»“æœè½¬å› BFloat16 å¹¶ç§»å› GPU
        # æˆªæ–­å¹¶æ³¨å†Œ(å³å›ºå®šä½)
        # å»ºè®®è½¬å› bf16 çœæ˜¾å­˜
        # 
        # è¿™ä¸€æ­¥ä¹Ÿæ˜¯ä¸ºäº†è®© TinyLoRA çš„å‚æ•°å’Œä¸»æ¨¡å‹ç²¾åº¦ä¿æŒä¸€è‡´
        
        target_dtype = torch.bfloat16

        self.register_buffer('U', U[:, :rank].to(original_device).to(target_dtype)) 
        self.register_buffer('S', torch.diag(S[:rank]).to(original_device).to(target_dtype))
        self.register_buffer('Vh', Vh[:rank, :].to(original_device).to(target_dtype))
        
        # å›ºå®šéšæœºçŸ©é˜µ P  (For TinyLoRA)
        self.register_buffer('P', torch.randn(u, rank, rank, device=original_device, dtype=target_dtype))
        
        # å”¯ä¸€çš„å¯è®­ç»ƒå‚æ•° v (å¦‚æœä¼ å…¥ shared_v åˆ™å®ç°å‚æ•°å…±äº«)

        if shared_v is not None:
            # å¤„ç†å¤šå¡/å¤šè®¾å¤‡æ—¶çš„å…±äº«å¼•ç”¨é—®é¢˜
            if shared_v.device != original_device:
                 # å¦‚æœè®¾å¤‡ä¸ä¸€è‡´ï¼Œåˆ›å»ºä¸€ä¸ªä¸å…±äº«æ¢¯åº¦çš„å‰¯æœ¬ï¼ˆè¿™æ˜¯ä¸€ä¸ªå¦¥åï¼Œä¸¥è°¨çš„å…±äº«éœ€è¦ DDP åŒæ­¥ï¼‰
                 self.v = nn.Parameter(shared_v.data.to(original_device).clone())
            else:
                 self.v = shared_v
        else:
            self.v = nn.Parameter(torch.zeros(u, device=original_device, dtype=target_dtype))

    def forward(self, x):
        # è®¡ç®— TinyLoRA çš„å¢é‡çŸ©é˜µ R
        R = torch.einsum('u, urr -> rr', self.v, self.P)
        # é‡ç»„å¢é‡æƒé‡
        delta_W = self.U @ self.S @ R @ self.Vh
        # å‰å‘ä¼ æ’­ï¼šx * (W + delta_W)^T
        return self.base_layer(x) + x @ delta_W.t()


def apply_tiny_lora(model, shared_v):
    """
    éå†æ¨¡å‹ï¼Œå°†æ‰€æœ‰ç›®æ ‡ Linear å±‚æ›¿æ¢ä¸º TinyLoRALinearï¼Œ
    å¹¶å¼ºåˆ¶ä½¿ç”¨åŒä¸€ä¸ª shared_vï¼Œå®ç°è®ºæ–‡ä¸­çš„ Tiling (å…¨å‚æ•°å…±äº«)ã€‚
    """
    # Qwen/Llama çš„ç›®æ ‡æ¨¡å—åç§°é€šå¸¸åŒ…å«è¿™äº›
    target_suffixes = ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
    
    # è®¡æ•°å™¨
    replaced_count = 0
    
    # é€’å½’å‡½æ•°ï¼šéå†å­æ¨¡å—
    for name, child in model.named_children():
        # å¦‚æœæ˜¯ç›®æ ‡ Linear å±‚
        if isinstance(child, nn.Linear) and any(name.endswith(s) for s in target_suffixes):
            # 1. åˆ›å»º TinyLoRA å±‚ï¼Œä¼ å…¥ global_v
            # æ³¨æ„ï¼šoriginal_layer=childï¼Œshared_v=shared_v
            new_layer = TinyLoRALinear(child, rank=2, u=16, shared_v=shared_v)
            
            # 2. æ›¿æ¢æ‰åŸæ¨¡å— (Monkey Patch)
            setattr(model, name, new_layer)
            replaced_count += 1
            print(f"å·²æ›¿æ¢: {name} -> TinyLoRA (Shared)")
            
        else:
            # ç»§ç»­é€’å½’éå†å­æ¨¡å— (ä¾‹å¦‚ model.layers.0.self_attn...)
            apply_tiny_lora(child, shared_v)
            
    return replaced_count

# ========== æ‰§è¡Œæ›¿æ¢ ==========
print("æ­£åœ¨åº”ç”¨ TinyLoRA Tiling (å‚æ•°å…±äº«)...")
# global_v å·²ç»åœ¨ä½ ä¹‹å‰çš„ä»£ç ä¸­å®šä¹‰äº†
total_replaced = apply_tiny_lora(model, global_v)
print(f"æ›¿æ¢å®Œæˆï¼å…±æ›¿æ¢äº† {total_replaced} ä¸ªæ¨¡å—ã€‚")

# ========== å…³é”®æ­¥éª¤ï¼šå†»ç»“é™¤ v ä»¥å¤–çš„æ‰€æœ‰å‚æ•° ==========
print("æ­£åœ¨å†»ç»“æ¨¡å‹å‚æ•°...")

for name, param in model.named_parameters():
    # åªæœ‰ global_v éœ€è¦æ¢¯åº¦ï¼Œå…¶ä»–å…¨éƒ¨å†»ç»“
    # æ³¨æ„ï¼šå› ä¸ºæˆ‘ä»¬æ˜¯æŠŠ shared_v ä¼ è¿›å»çš„ï¼Œid(param) == id(global_v)
    if param is global_v:
        param.requires_grad = True
    else:
        param.requires_grad = False

import re
import subprocess
import tempfile

def code_reward_func(completions, solution, **kwargs):
    """
    completions: list[str], æ¨¡å‹ç”Ÿæˆçš„å›å¤åˆ—è¡¨
    solution: list[str], æ•°æ®é›†é‡Œçš„å‚è€ƒç­”æ¡ˆï¼ˆæˆ–è€…æµ‹è¯•ç”¨ä¾‹çš„è¾“å…¥/è¾“å‡ºï¼‰
    æ³¨æ„ï¼šè¿™é‡Œçš„æ•°æ®é›†æ ¼å¼éœ€è¦ä½ æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ã€‚å‡è®¾ dataset é‡Œæœ‰ 'input' å’Œ 'output' å­—æ®µã€‚
    """
    rewards = []
    
    # å‡è®¾ dataset çš„ç»“æ„æ˜¯ {'problem': ..., 'test_cases': [{'in': '...', 'out': '...'}]}
    # è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬å‡è®¾ solution å°±æ˜¯é¢„æœŸè¾“å‡ºï¼Œcompletions æ˜¯ä»£ç 
    
    for completion, sol in zip(completions, solution):
        # 1. æå–ä»£ç å— (```cpp ... ```)
        code_match = re.search(r"```(?:cpp|c\+\+)?\n(.*?)```", completion, re.DOTALL)
        if not code_match:
            rewards.append(0.0) # æ²¡å†™ä»£ç ï¼Œ0åˆ†
            continue
            
        code = code_match.group(1)
        
        # 2. ç¼–è¯‘ä¸è¿è¡Œ (æ²™ç®±ç¯å¢ƒæ¨¡æ‹Ÿ)
        # è­¦å‘Šï¼šåœ¨ç”Ÿäº§ç¯å¢ƒä¸­è¯·ä½¿ç”¨ dockerï¼æœ¬åœ°è¿è¡Œæœ‰é£é™©ã€‚
        try:
            with tempfile.TemporaryDirectory() as temp_dir:
                src_path = f"{temp_dir}/main.cpp"
                exe_path = f"{temp_dir}/main"
                
                with open(src_path, "w") as f:
                    f.write(code)
                
                # ç¼–è¯‘
                compile_proc = subprocess.run(
                    ["g++", src_path, "-o", exe_path, "-O2"],
                    capture_output=True, text=True, timeout=5
                )
                if compile_proc.returncode != 0:
                    rewards.append(0.0) # ç¼–è¯‘å¤±è´¥
                    continue
                
                # è¿è¡Œæµ‹è¯• (å‡è®¾ sol æ˜¯ {'input': '1 2', 'output': '3'})
                # è¿™é‡Œä½ éœ€è¦è§£æ dataset é‡Œçš„æµ‹è¯•ç”¨ä¾‹
                # ä¼ªä»£ç ï¼š
                # run_proc = subprocess.run(
                #     [exe_path], input=sol['input'], capture_output=True, text=True, timeout=2
                # )
                # if run_proc.stdout.strip() == sol['output'].strip():
                #     rewards.append(1.0)
                # else:
                #     rewards.append(0.0)
                
                rewards.append(0.1) # æš‚æ—¶ç»™ä¸ªè¾›è‹¦åˆ†ï¼Œè®©ä½ è·‘é€šæµç¨‹

        except Exception as e:
            print(f"è¯„æµ‹å¼‚å¸¸: {e}")
            rewards.append(0.0)
            
    return rewards

# å½“ä½ ä½¿ç”¨ load_dataset("json", data_files="....jsonl") æ—¶ï¼Œ
# Hugging Face ä¼šé»˜è®¤æŠŠä½ æä¾›çš„è¿™ä¸ªæ–‡ä»¶å½’ç±»ä¸º train åˆ†åŒºï¼ˆè¿™æ˜¯å®ƒçš„é»˜è®¤è¡Œä¸ºï¼‰ã€‚
# æ³¨æ„ï¼šdata_files æŒ‡å‘ä½  convert_dataset.py ç”Ÿæˆçš„å…·ä½“æ–‡ä»¶è·¯å¾„
# split="train" å¾ˆé‡è¦ï¼å› ä¸º load_dataset é»˜è®¤è¿”å› DatasetDictï¼Œ
# è€Œ Trainer éœ€è¦çš„æ˜¯ Dataset å¯¹è±¡ï¼ŒæŒ‡å®š split="train" ç›´æ¥æ‹¿åˆ°æ•°æ®ã€‚
rl_dataset = load_dataset(
    "json", 
    data_files="./local_luogu_rl/luogu_rl_data.jsonl", 
    # ç¡®è®¤è¿™é‡Œçš„è·¯å¾„å’Œä½  convert_dataset.py é‡Œçš„ OUTPUT_FILE ä¸€è‡´
    split="train"
)

# 2. (å¯é€‰) æ‰“å°ä¸€æ¡æ•°æ®éªŒè¯ä¸€ä¸‹
print(f"æ•°æ®åŠ è½½æˆåŠŸï¼æ ·æœ¬æ•°é‡: {len(rl_dataset)}")
print(f"æ ·ä¾‹æ•°æ®: {rl_dataset[0]}")
# ========== é…ç½®å¹¶å¯åŠ¨ GRPO è®­ç»ƒ ==========
# é…ç½® GRPO
training_args = GRPOConfig(
    output_dir=OUTPUT_DIR,
    num_train_epochs=1,
    per_device_train_batch_size=1, # å•å¡æ˜¾å­˜ä¸å¤Ÿå°±è®¾ä¸º 1
    gradient_accumulation_steps=8, # ç´¯ç§¯æ¢¯åº¦æ¥æ¨¡æ‹Ÿå¤§ Batch
    learning_rate=1e-5,            # RL å­¦ä¹ ç‡é€šå¸¸è¦å°
    num_generations=4,             # Group Size (G): æ¯æ¬¡é‡‡æ · 4 ä¸ªç­”æ¡ˆ
    max_completion_length=512,     # ç”Ÿæˆçš„æœ€å¤§é•¿åº¦
    logging_steps=1,
    bf16=True,                     # å¼€å¯ BF16 åŠ é€Ÿ
)

# åˆå§‹åŒ–è®­ç»ƒå™¨
trainer = GRPOTrainer(
    model=model,
    reward_funcs=code_reward_func, # ä½ çš„åˆ¤é¢˜å‡½æ•°
    args=training_args,
    train_dataset=rl_dataset,   # å¤„ç†å¥½çš„æ•°æ®
    processing_class=tokenizer,    # Tokenizer
)

# å¼€å§‹è®­ç»ƒï¼
print("ğŸš€ å¼€å§‹ TinyLoRA-RL è®­ç»ƒ...")
trainer.train()

# ä¿å­˜ LoRA (åªä¿å­˜é‚£ä¸ª v å‘é‡)
# æ³¨æ„ï¼špeft çš„ save_pretrained å¯èƒ½ä¸è®¤ä½ çš„è‡ªå®šä¹‰å±‚
# ä½ å¯èƒ½éœ€è¦æ‰‹åŠ¨ä¿å­˜ global_v
torch.save(global_v, f"{OUTPUT_DIR}/tiny_lora_v.pt")
print("è®­ç»ƒå®Œæˆï¼Œå‚æ•°å·²ä¿å­˜ï¼")