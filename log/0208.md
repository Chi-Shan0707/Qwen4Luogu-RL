这份文档总结了你在复现 **TinyLoRA + RL (GRPO) on Qwen2.5-Coder-3B (4-bit)** 过程中的所有关键踩坑记录。这是一份非常宝贵的实战经验总结，涵盖了从数据处理、模型修改到训练启动的全流程。

---

# 🛠️ LuoguQwen-RL 复现踩坑与错误实录

**项目背景**：在显存受限环境下（3B 模型 + 4-bit 量化），复现 TinyLoRA 论文（全网仅 16 个可训练参数），并使用 GRPO 强化学习进行代码生成训练。

---

## 一、 模型修改与 TinyLoRA 实现篇

### 1. SVD 分解的精度陷阱

* **报错信息**：`NotImplementedError: "svd_cuda_gesvdj" not implemented for 'BFloat16'`
* **现象**：尝试对 4-bit 解包后的 BF16 权重直接在 GPU 上做 SVD。
* **原因**：PyTorch 的 CUDA SVD 实现不支持半精度（BF16/FP16），且 GPU SVD 对量化噪声非常敏感，容易计算失败。
* **解决方案**：
1. **Dequantize**：将 4-bit (`torch.uint8`) 解包。
2. **转 FP32 & CPU**：`W_cpu = W_real.float().cpu()`。
3. **计算 SVD**：在 CPU 上用 FP32 算完。
4. **回传**：将结果  转回 BF16 并存入 GPU Buffer。



### 2. 磁盘 IO 爆炸（Swap Thrashing）

* **现象**：运行 `train_rl.py` 时，磁盘活动飙升至 100%，系统卡顿。
* **原因**：在循环处理每一层时，解包后的 FP32 权重矩阵（巨大）没有被及时释放，导致内存溢出，操作系统开始疯狂读写 Swap（虚拟内存）。
* **解决方案**：
* 显式调用 `del W_real`, `del W_cpu`。
* 调用 `torch.cuda.empty_cache()`。
* 确保变量作用域及时结束。



### 3. 参数共享失败（伪 Tiling）

* **代码逻辑**：`self.v = nn.Parameter(shared_v.data.to(device).clone())`
* **现象**：程序能跑，但实际上每一层都创建了一个独立的 `v`，全网有 252 个 `v` 在训练，而不是全局共享的 1 个。
* **原因**：
1. `global_v` 初始化在 CPU，而模型在 GPU，导致必须 `.to(device)`。
2. `.clone()` 或再次包裹 `nn.Parameter()` 会切断引用关系，创建副本。


* **解决方案**：
1. **初始化**：确保 `global_v` 直接在 GPU 上创建 (`device=model.device`)。
2. **引用**：直接赋值 `self.v = shared_v`，严禁使用 `clone()`。



---

## 二、 训练框架与 PEFT 篇

### 4. 纯量化模型无法训练

* **报错信息**：`ValueError: You cannot perform fine-tuning on purely quantized models...`
* **原因**：HF Trainer 检测到模型是 4-bit 加载的，且没有经过 PEFT 处理。4-bit 模型的 LayerNorm 等层默认不支持梯度计算。
* **解决方案**：
* 引入：`from peft import prepare_model_for_kbit_training`
* 执行：在应用 TinyLoRA 前，先运行 `model = prepare_model_for_kbit_training(model)`。这会将 LayerNorm 转为 FP32 并开启梯度检查点。



### 5. 递归替换的输出疑惑

* **现象**：控制台疯狂打印 `已替换: q_proj...`，且同一个名字出现多次。
* **误区**：以为程序死循环或逻辑错误。
* **真相**：正常现象。Qwen-3B 有 36 层，每层有 7 个 Linear 模块，共需替换约 252 次。打印的是局部名称，不是全路径。

---

## 三、 数据处理篇 (Data Pipeline)

### 6. 正则表达式的脆弱性

* **初期问题**：代码写死匹配“输入样例”四个字，但洛谷数据中实际格式是 `**输入：**` 或 `Input:`。导致提取率为 0。
* **进阶问题**：使用 `strip()` 清洗数据时，意外删除了输入样例中间的换行符（`\n`），导致 `cin >> a >> b` 变成了读取 `a` 和 `b` 粘在一起的字符串。
* **解决方案**：
* **锚点定位**：先找 `## 样例` 缩小搜索范围。
* **非贪婪正则**：使用 `([\s\S]*?)` 配合 `**输入：**` 等多种 Pattern。
* **保护换行**：仅 `strip()` 首尾，保留中间结构。



### 7. 数据集格式认知

* **误区**：以为 RL 训练需要 `reference`（标准答案代码）。
* **修正**：**RL 不需要 Reference**。RL 的核心是 Reward Function，只要模型生成的代码能过测试用例（Test Cases）即可，不需要模仿标准答案的写法。
* **脏数据**：部分测试用例包含中文描述（非纯数据），会导致评测失败。需增加 `contains_chinese` 过滤。

### 8. `load_dataset` 的 Split 陷阱

* **问题**：直接加载 jsonl 文件得到的是 `DatasetDict`，传给 Trainer 会报错。
* **解决方案**：必须指定 `split="train"`，如 `load_dataset("json", data_files="...", split="train")`。

---

## 四、 强化学习与奖励函数篇 (Reward Function)

### 9. `freopen` 导致的评测 0 分

* **现象**：模型生成的代码喜欢加 `freopen("input.txt", ...)`，导致在标准输入流（stdin）评测时读取文件失败。
* **解决方案**：在编译前使用正则暴力删除：`re.sub(r'freopen\s*\(.*?\);', '', code)`。

### 10. 僵尸进程与死循环

* **风险**：模型生成的代码可能包含 `while(1)` 死循环，导致训练卡死或 CPU 100%。
* **解决方案**：在 `subprocess.run` 中必须设置 `timeout=2`（秒），超时即判负。

### 11. 临时文件冲突

* **风险**：并发采样（`num_generations=4`）时，如果所有进程都写同一个 `solution.cpp`，会发生读写冲突。
* **解决方案**：必须使用 `tempfile.TemporaryDirectory()` 为每次评测创建独立的沙箱环境。

---

## 五、 核心概念备忘

1. **FP4 / NF4 (`uint8`)**：这是“压缩包”，**不可直接计算**。必须解包（Dequantize）成 BF16/FP32 才能进行 SVD 或其他数学运算。
2. **BF16 vs FP32**：
* 矩阵乘法（Linear）：用 BF16（快）。
* SVD 分解、LayerNorm：用 FP32（稳）。
* TinyLoRA 参数：用 BF16（与主干一致）。


3. **Tiling (平铺)**：
* 物理上：全网所有层共享同一个内存地址的 `global_v`。
* 实现上：必须直接赋值引用 (`self.v = shared_v`)，不能有任何 Copy 操作。